<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Yunze's blog</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content><meta name=generator content="Hugo 0.101.0"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/ananke/css/main.min.css><link href=/categories/index.xml rel=alternate type=application/rss+xml title="Yunze's blog"><link href=/categories/index.xml rel=feed type=application/rss+xml title="Yunze's blog"><meta property="og:title" content="Categories"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://arthuryunze.github.io/categories/"><meta itemprop=name content="Categories"><meta itemprop=description content><meta name=twitter:card content="summary"><meta name=twitter:title content="Categories"><meta name=twitter:description content></head><body class="ma0 avenir bg-near-white"><header><div class="pb3-m pb6-l bg-black"><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">Yunze's blog</a><div class="flex-l items-center"><div class=ananke-socials></div></div></div></nav><div class="tc-l pv3 ph3 ph4-ns"><h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">Categories</h1></div></div></header><main class=pb7 role=main><article class="cf pa3 pa4-m pa4-l"><div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links mid-gray"></div></article><div class="mw8 center"><section class=ph4><h2 class=f1><a href=/categories/english class="link blue hover-black">Category: english</a></h2><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2019-08-02-month-names/ class="link black dim">Month Names</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">Where do the month names come from?
Name Comes form Who or what? Why? January Janus God of Doors This month opens the year. February februo purify This was a Roman month of sacrifices and purification. March Mars God of War Start of year for soldiers (no fighting during winter) April aperire open This is the month when trees open their leaves. May Maia Goddess of Growth This is the month when plants really start to grow.</div></div></div><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2019-08-02-what-do-a.m.-and-p.m.-stand-for/ class="link black dim">What Do A.M. And P.M. Stand For?</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">Most English speakers know that a.m. refers to the hours from midnight and noon, and p.m. to the hours from noon and midnight. But what do these ubiquitous abbreviations stand for?
The term we associate with the morning, a.m., is an abbreviation the Latin phrase ante merīdiem meaning “before midday”; p.m. is an abbreviation of post merīdiem, meaning—you guessed it—“after midday.” These two terms help keep ambiguity at bay in the 12-hour time system.</div></div></div><h2 class=f1><a href=/categories/github-math class="link blue hover-black">Category: github-math</a></h2><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-20-github-pages%E6%B7%BB%E5%8A%A0%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E6%94%AF%E6%8C%81/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">首先介绍一下Mathjax，Mathjax是一个开源js引擎，用于在浏览器中显示数学公式.
Mathjax MathJax | Beautiful math in all browsers.
A JavaScript display engine for mathematics that works in all browsers.
No more setup for readers. It just works.
适用于所有浏览器的数学JavaScript显示引擎。
不需要更多的设置就可以工作。
在GitHub Pages中的设置方法 找到自己jekll的主题配置文件，一般配置文件在本机主目录~/gems/gems/对应的主题路径下。(若使用remote_theme模式，可以到相应主题的GitHub主页copy相关文件。) 例如本Blog使用的thelehhman/texture主题，一般来说，_layout路径下可以配置各种页面的样式，可以看到其中每个配置文件都引入了_include路径下的head.html文件，为了我们在各种页面中都可以使用数学公式，可以在header.html文件中更改&lt;head>就可以更改每种页面的样式.
(如果希望只在部分页面使用Mathjax，可更改_layout路径下相应的文件。) 在MathJax官网中，找到它的js脚本配置如下: &lt;script src="https://polyfill.io/v3/polyfill.min.js?features=es6">&lt;/script> &lt;script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">&lt;/script> 由于Mathjax源码设置在国外服务器，直接添加此代码会导致在国内打开网页速度变得巨慢，所以，我们可以使用国内托管的Mathjax源码服务器，或者在有服务器的条件下自己搭建镜像服务器.
在这里找到了国内的一个托管服务器，mathjax | BootCDN - Bootstrap 中文网开源项目免费 CDN 加速服务
用此网站提供的地址替换掉上面代码的地址. 此时，在markdown文件中是只支持单行公式的，出于方便考虑，我们需要添加$ 公式 $ 的行内公式，添加相关配置后最终代码如下. &lt;script src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"> &lt;/script> &lt;script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], inlineMath: [['$','$']] } }); &lt;/script> 将其复制到对应html文件中即可使用.</div></div></div><h2 class=f1><a href=/categories/jekyll-update class="link blue hover-black">Category: jekyll-update</a></h2><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2019-07-15-welcome-to-jekyll/ class="link black dim">Welcome to Jekyll!</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.
To add new posts, simply add a file in the _posts directory that follows the convention YYYY-MM-DD-name-of-post.</div></div></div><h2 class=f1><a href=/categories/linux class="link blue hover-black">Category: linux</a></h2><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2019-07-18-dos2unix-unixlinux-command/ class="link black dim">dos2unix-Unix, Linux Command</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">NAME dos2unix - DOS/MAC to UNIX text file format converter
DESCRIPTION The program that converts plain text files in DOS/MAC format to UNIX format.
命令介绍 dos2unix命令用来将DOS格式的文本文件转换成UNIX格式的（DOS/MAC to UNIX text file format converter）。DOS下的文本文件是以\r\n作为断行标志的，表示成十六进制就是0D 0A。而Unix下的文本文件是以\n作为断行标志的，表示成十六进制就是 0A。DOS格式的文本文件在Linux底下，用较低版本的vi打开时行尾会显示^M，而且很多命令都无法很好的处理这种格式的文件，如果是个shell脚本，。而Unix格式的文本文件在Windows下用Notepad打开时会拼在一起显示。因此产生了两种格式文件相互转换的需求，对应的将UNIX格式文本文件转成成DOS格式的是unix2dos命令。
常用参数 将DOS格式文本文件转换成Unix格式，最简单的用法就是dos2unix直接跟上文件名。
格式：dos2unix file
如果一次转换多个文件，把这些文件名直接跟在dos2unix之后。（注：也可以加上-o参数，也可以不加，效果一样）
格式：dos2unix file1 file2 file3
格式：dos2unix -o file1 file2 file3
上面在转换时，都会直接在原来的文件上修改，如果想把转换的结果保存在别的文件，而源文件不变，则可以使用-n参数。
格式：dos2unix oldfile newfile
如果要保持文件时间戳不变，加上-k参数。所以上面几条命令都是可以加上-k参数来保持文件时间戳的。
格式：dos2unix -k file
格式：dos2unix -k file1 file2 file3
格式：dos2unix -k -o file1 file2 file3
格式：dos2unix -k -n oldfile newfile</div></div></div><h2 class=f1><a href=/categories/ml class="link blue hover-black">Category: ml</a></h2><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-20-softmax%E5%87%BD%E6%95%B0/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">Softmax函数 在数学，尤其是概率论和相关领域中，Softmax函数，或称归一化指数函数，是逻辑函数的一种推广。它能将一个含任意实数的K维向量z “压缩”到另一个K维实向量$ \sigma{z} $中，使得每一个元素的范围都在(0,1)之间，并且所有元素的和为1(也可视为一个 (k-1)维的hyperplan，因为总和为1，所以是subspace)。该函数的形式通常按下面的式子给出：
$$ {\displaystyle \sigma (\mathbf {z} ){j}={\frac {e^{z{j}}}{\sum {k=1}^{K}e^{z{k}}}}} for j = 1, …, K. $$
Python example：
>>> import numpy as np >>> a = [1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0] >>> np.exp(a) / np.sum(np.exp(a)) array([0.02364054, 0.06426166, 0.1746813, 0.474833, 0.02364054,0.06426166, 0.1746813]) Reference: Softmax函数 - 维基百科，自由的百科全书</div></div></div><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-24-loss-function/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">What’s a Loss Function? 什么是损失函数？
At its core, a loss function is incredibly simple: it’s a method of evaluating how well your algorithm models your dataset.
损失函数的核心非常简单：它是评价你的算法效果有多好的方法。
Different Types and Flavors of Loss Functions A lot of the loss functions that you see implemented in machine learning can get complex and confusing. Consider this paper from late 2017, entitled A Semantic Loss Function for Deep Learning with Symbolic Knowledge. There’s more in that title that I don’t understand than I do.</div></div></div><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-28-machinelearning%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">线性回归 线性模型 基本形式 线性模型(Linear model)试图学得一个通过属性的线性组合来进行预测的函数，即
$$ f(x)=w_1x_1+w_2x_2+&mldr;+w_dx_d+b $$
一般用向量形式写成
$$ f(x)=w^Tx+b $$
其中$ w=(w_1;w_2;&mldr;;w_d) $.w和b学得之后，模型就得以确定。
线性模型有很好的可解释性。
线性回归 &ldquo;线性回归&rdquo; (linear regression)试图学得一个线性模型以尽可能准确地预测实值输出标记。
均方误差(2.2) 是回归任务中最常用的性能度量
均方误差有非常好的几何意义。它对应了常用的欧几里得距离或简称"欧氏距离" (Euclidean distance). 基于均方误差最小化来进行模型求解的方法称为"最小二乘法" (least squ町e method).
在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小.
求解w,b过程，称为线性回归模型的最小二乘"参数估计" (parameter estimation).
凸函数的任何极小值也是最小值。严格凸函数最多有一个最小值。 凸函数 - 维基百科，自由的百科全书
两种算法：
经典算法——最小二乘法 深度学习——梯度下降法 用两种方法分别实现了线性回归 项目传到GitHub Learn_MXNet/LinearRegression.ipynb at master · arthuryunze/Learn_MXNet 线性回归理解（附纯python实现）_Python_快来学习鸭～～～-CSDN博客</div></div></div><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-05-16-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%B8%89%E7%A7%8D%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%AD%E7%BB%83%E9%9B%86%E9%AA%8C%E8%AF%81%E9%9B%86%E6%B5%8B%E8%AF%95%E9%9B%86/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">机器学习中的数据集 训练集、验证集、测试集 在人工智能技术中，通常有三种常用的数据集：训练集、验证集、测试集。
先用一个不恰当的比喻来说明3种数据集之间的关系：
训练集相当于上课学知识 验证集相当于课后的的练习题，用来纠正和强化学到的知识 测试集相当于期末考试，用来最终评估学习效果 训练集 训练集（Training Dataset）是用来训练模型使用的。
机器学习的七个步骤 验证集 当我们的模型训练好之后，我们并不知道他的表现如何。
这个时候就可以使用验证集（Validation Dataset）来看看模型在新数据（验证集和测试集是不同的数据）上的表现如何。同时通过调整超参数，让模型处于最好的状态。
验证集有2个主要的作用：
评估模型效果，为了调整超参数而服务 调整超参数，使得模型在验证集上的效果最好 说明：
验证集不像训练集和测试集，它是非必需的。如果不需要调整超参数，就可以不使用验证集，直接用测试集来评估效果。 验证集评估出来的效果并非模型的最终效果，主要是用来调整超参数的，模型最终效果以测试集的评估结果为准。 测试集 当我们调好超参数后，就要开始「最终考试」了。我们通过测试集（Test Dataset）来做最终的评估。
通过测试集的评估，我们会得到一些最终的评估指标，例如：准确率、精确率、召回率、F1等。
如何合理划分数据集 下面的数据集划分方式主要针对「留出法」的验证方式，除此之外还有其他的交叉验证法，详情见下文 — — 交叉验证法。
数据划分的方法并没有明确的规定，不过可以参考3个原则：
对于小规模样本集（几万量级），常用的分配比例是 60% 训练集、20% 验证集、20% 测试集。 对于大规模样本集（百万级以上），只要验证集和测试集的数量足够即可，例如有 100w 条数据，那么留 1w 验证集，1w 测试集即可。1000w 的数据，同样留 1w 验证集和 1w 测试集。 超参数越少，或者超参数很容易调整，那么可以减少验证集的比例，更多的分配给训练集。 交叉验证法 为什么要用交叉验证法？
假如我们教小朋友学加法：1个苹果+1个苹果=2个苹果
当我们再测试的时候，会问：1个香蕉+1个香蕉=几个香蕉？
如果小朋友知道「2个香蕉」，并且换成其他东西也没有问题，那么我们认为小朋友学习会了「1+1=2」这个知识点。
如果小朋友只知道「1个苹果+1个苹果=2个苹果」，但是换成其他东西就不会了，那么我们就不能说小朋友学会了「1+1=2」这个知识点。
评估模型是否学会了「某项技能」时，也需要用新的数据来评估，而不是用训练集里的数据来评估。这种「训练集」和「测试集」完全不同的验证方法就是交叉验证法。
3 种主流的交叉验证法 留出法（Holdout cross validation） 上文提到的，按照固定比例将数据集静态的划分为训练集、验证集、测试集。的方式就是留出法。
留一法（Leave one out cross validation） 每次的测试集都只有一个样本，要进行 m 次训练和预测。 这个方法用于训练的数据只比整体数据集少了一个样本，因此最接近原始样本的分布。但是训练复杂度增加了，因为模型的数量与原始数据样本数量相同。 一般在数据缺乏时使用。</div></div></div><h2 class=f1><a href=/categories/ml-mxnet class="link blue hover-black">Category: ml-mxnet</a></h2><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-20-mxnet%E5%AD%A6%E4%B9%A0-%E4%B8%80/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">系统环境：
Windows10
python3
MXNet v1.5.1 cpu版本
Anaconda jupyterLab 1.2.6
国际惯例，从mnist数据集开始。
Loading Data——导入mnist手写体数据集 import mxnet as mx # Fixing the random seed mx.random.seed(42) mnist = mx.test_utils.get_mnist() 注意，Windows环境下，运行完成后将在当前目录下载四个.qz格式文件，若下载被中断，则无法运行后续代码。
解决方法：删除不完整的.qz文件从新下载。Linux系统下该文件位置在~/.keras/datasets路径下，使用命令rm -rf "dataset name"删除。
# 训练批次 batch_size = 100 # 初始化两个迭代器，一个用于训练数据，另一个用于测试数据。 train_data = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], batch_size, shuffle=True) val_data = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size) MXNet Data iterators： MXNet数据迭代器
对于大批量数据，不可能预加载整个数据集，MXNet Data iterators可将输入数据流式传输到MXNet训练算法中。
一个批次的图像通常表示为一个4维数组(batch_size, num_channels, width, height)
Approaches——方法(CNN) CNN主要由两种网络层构成：
卷积层和池化层
卷积层 单个卷积层由一个或多个过滤器组成，每个过滤器起*特征检测器(feature detector)*的作用。
在训练过程中，CNN学习这些过滤器的适当表示形式(参数)。
CNN通过应用非线性函数对卷积层的输出进行转换(transform)。
池化层 A pooling layer serves to make the CNN translation invariant</div></div></div><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-21-mxnet%E5%AD%A6%E4%B9%A0-%E4%BA%8C/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">在上一节，我们已经搭好了LeNet。
现在，我们要开始使用数据训练这个网络，以使它找到合适的参数。
我们将使用超参数训练LeNet。
若使用GPU进行运算，我们只需要将mx.cpu()更改为mx.gpu()，而MXNet会处理其余的工作。我们将在10个时间段(epoch)后停止训练。
建议使用GPU进行运算，LeNet比MLP(多层感知机)更复杂，计算量更大。GPU可大大加快计算速度。
为了方便，我的环境使用了CPU版本的MXNet。速度会稍慢，但不影响后续代码。
注意CPU版本和GPU版本安装时是不同的，安装步骤可以查看MXNet官网。
Initialize parameters and optimizer——初始化参数和优化器 初始化网络参数如下：
# set the context on GPU is available otherwise CPU ctx = [mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()] net.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx) trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.03}) Training——训练 # Use Accuracy as the evaluation metric. metric = mx.metric.Accuracy() softmax_cross_entropy_loss = gluon.loss.SoftmaxCrossEntropyLoss() for i in range(epoch): # Reset the train data iterator. train_data.reset() # Loop over the train data iterator. for batch in train_data: # Splits train data into multiple slices along batch_axis # and copy each slice into a context.</div></div></div><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-23-face-detectionmtcnn-%E5%AD%A6%E4%B9%A0-%E4%B8%80/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">Face Detection 人脸检测 对于人类而言，这是一个微不足道的问题，近来也已经被经典的基于特征的技术（例如级联分类器）合理地解决了。最近，深度学习方法已在标准的基准人脸检测数据集上取得了最先进的结果。一个例子是多任务级联卷积神经网络(Multi-task Cascade Convolutional Neural Network)，简称MTCNN。
MTCNN网络结构 该网络使用具有三个网络的级联结构。 首先将图像缩放到不同大小的范围（称为图像金字塔），然后第一个模型（建议网络或P-Net）提出候选的面部区域，第二个模型（Refine网络或R-Net）过滤边界框 ，第三个模型（输出网络或O-Net）提出了人脸标志。
第一个网络是一个浅层神经网络（后简称pnet） => 产生初步候选框 第二个网络是一个“more complex CNN“相较pnet更为复杂的网络（后简称rnet）=> 从初步候选框中筛选掉大量的不包括人脸的框
第三个网络是一个“more powerful CNN”相较rnet更为强大的网络（后简称onet）=> 进一步优化结果以及产生五个面部特征点（双眼，鼻尖，嘴角）
mtcnn库 GitHub上发现，已经有同学做好了MTCNN相应的库
ipazc/mtcnn: MTCNN face detection implementation for TensorFlow, as a PIP package.
我们先简单使用一下：
用笔记本自带摄像头拍摄一张照片，用opencv库导入。
from mtcnn import MTCNN import cv2 img = cv2.cvtColor(cv2.imread("WIN_20200223_17_44_49_Pro.jpg"), cv2.COLOR_BGR2RGB) detector = MTCNN() detector.detect_faces(img) 我们可以得到一个list格式的数据
[{'box': [480, 214, 234, 309], 'confidence': 0.9999535083770752, 'keypoints': {'left_eye': (536, 330), 'right_eye': (643, 334), 'nose': (583, 402), 'mouth_left': (543, 453), 'mouth_right': (633, 456)}}] 从这个list可以看出</div></div></div><h2 class=f1><a href=/categories/programlanguage-haskell class="link blue hover-black">Category: programlanguage-haskell</a></h2><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-03-01-haskell-learn-%E4%B8%80/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">Types and Typeclasses ghci 交互式shell中，:t判断变量类型。
:t 'a' 'a' :: Char :: is read as &ldquo;has type of&rdquo;.
函数类型显式声明 一般来说，Haskell有类型推断系统，不需要我们显式声明。但是，我们定义函数时会使用显式声明的办法。
除了编写非常短的函数之外，这通常被认为是一个好的实践。
This is generally considered to be good practice except when writing very short functions.
addThree :: Int -> Int -> Int -> Int addThree x y z = x + y + z 前三个Int是参数类型，最后一个是输出类型。 参数之间用->分隔，并且参数和返回类型之间没有特殊区别。
product [1..10] 120 1到10的乘积
head takes a list of any type and returns the first element</div></div></div><h2 class=f1><a href=/categories/tool-git class="link blue hover-black">Category: tool-git</a></h2><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-19-git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">项目提交时: git add -A 提交所有变化 git add -u 提交被修改(modified)和被删除(deleted)文件，不包括新文件(new) git add . 提交新文件(new)和被修改(modified)文件，不包括被删除(deleted)文件 git pull 拉取远程仓库,覆盖本地文件,本地其它改动不会受到影响.
项目更改时: git commit -m "本功能全部完成" 提交后
若需要撤回commit并保留代码
可执行 git reset --soft HEAD^ 以撤销上次commit
HEAD^的意思是上一个版本，也可以写成HEAD~1
如果进行了2次commit，想都撤回，可以使用HEAD~2
几个参数:
--mixed
不删除工作空间改动代码，撤销commit，并且撤销git add . 操作 这个为默认参数,即 git reset --mixed HEAD^ 和 git reset HEAD^ 效果是一样的。 --soft
不删除工作空间改动代码，撤销commit，不撤销git add . --hard
删除工作空间改动代码，撤销commit，撤销git add . 注意完成这个操作后，就恢复到了上一次的commit状态。
如果commit注释写错了，只是想改一下注释，只需要: git commit --amend
此时会进入默认vim编辑器，修改注释完毕后保存就好了。
项目拉取时 git pull 不带任何参数，拉取当前分支。
问题 fatal: refusing to merge unrelated histories</div></div></div><h2 class=f1><a href=/categories/tool-markdown class="link blue hover-black">Category: tool-markdown</a></h2><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-13-markdown%E8%AF%AD%E6%B3%95/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">this is ======title this is ----- title this is test > 引用内容
>> 嵌套引用
**加粗内容** 加粗
![AltText](/path/to/img.jpg) 插入图片</div></div></div></section></div></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://arthuryunze.github.io/>&copy; Yunze's blog 2022</a><div><div class=ananke-socials></div></div></div></footer></body></html>