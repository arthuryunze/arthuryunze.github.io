<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>ML | Yunze's blog</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content><meta name=generator content="Hugo 0.101.0"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/ananke/css/main.min.css><link href=/categories/ml/index.xml rel=alternate type=application/rss+xml title="Yunze's blog"><link href=/categories/ml/index.xml rel=feed type=application/rss+xml title="Yunze's blog"><meta property="og:title" content="ML"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://arthuryunze.github.io/categories/ml/"><meta itemprop=name content="ML"><meta itemprop=description content><meta name=twitter:card content="summary"><meta name=twitter:title content="ML"><meta name=twitter:description content></head><body class="ma0 avenir bg-near-white"><header><div class="pb3-m pb6-l bg-black"><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">Yunze's blog</a><div class="flex-l items-center"><div class=ananke-socials></div></div></div></nav><div class="tc-l pv3 ph3 ph4-ns"><h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">ML</h1></div></div></header><main class=pb7 role=main><article class="cf pa3 pa4-m pa4-l"><div class="measure-wide-l center f4 lh-copy nested-copy-line-height nested-links mid-gray"><p>Below you will find pages that utilize the taxonomy term “ML”</p></div></article><div class="mw8 center"><section class="flex-ns flex-wrap justify-around mt5"><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-20-softmax%E5%87%BD%E6%95%B0/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">Softmax函数 在数学，尤其是概率论和相关领域中，Softmax函数，或称归一化指数函数，是逻辑函数的一种推广。它能将一个含任意实数的K维向量z “压缩”到另一个K维实向量$ \sigma{z} $中，使得每一个元素的范围都在(0,1)之间，并且所有元素的和为1(也可视为一个 (k-1)维的hyperplan，因为总和为1，所以是subspace)。该函数的形式通常按下面的式子给出：
$$ {\displaystyle \sigma (\mathbf {z} ){j}={\frac {e^{z{j}}}{\sum {k=1}^{K}e^{z{k}}}}} for j = 1, …, K. $$
Python example：
>>> import numpy as np >>> a = [1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0] >>> np.exp(a) / np.sum(np.exp(a)) array([0.02364054, 0.06426166, 0.1746813, 0.474833, 0.02364054,0.06426166, 0.1746813]) Reference: Softmax函数 - 维基百科，自由的百科全书</div></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-24-loss-function/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">What’s a Loss Function? 什么是损失函数？
At its core, a loss function is incredibly simple: it’s a method of evaluating how well your algorithm models your dataset.
损失函数的核心非常简单：它是评价你的算法效果有多好的方法。
Different Types and Flavors of Loss Functions A lot of the loss functions that you see implemented in machine learning can get complex and confusing. Consider this paper from late 2017, entitled A Semantic Loss Function for Deep Learning with Symbolic Knowledge. There’s more in that title that I don’t understand than I do.</div></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-28-machinelearning%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">线性回归 线性模型 基本形式 线性模型(Linear model)试图学得一个通过属性的线性组合来进行预测的函数，即
$$ f(x)=w_1x_1+w_2x_2+&mldr;+w_dx_d+b $$
一般用向量形式写成
$$ f(x)=w^Tx+b $$
其中$ w=(w_1;w_2;&mldr;;w_d) $.w和b学得之后，模型就得以确定。
线性模型有很好的可解释性。
线性回归 &ldquo;线性回归&rdquo; (linear regression)试图学得一个线性模型以尽可能准确地预测实值输出标记。
均方误差(2.2) 是回归任务中最常用的性能度量
均方误差有非常好的几何意义。它对应了常用的欧几里得距离或简称"欧氏距离" (Euclidean distance). 基于均方误差最小化来进行模型求解的方法称为"最小二乘法" (least squ町e method).
在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小.
求解w,b过程，称为线性回归模型的最小二乘"参数估计" (parameter estimation).
凸函数的任何极小值也是最小值。严格凸函数最多有一个最小值。 凸函数 - 维基百科，自由的百科全书
两种算法：
经典算法——最小二乘法 深度学习——梯度下降法 用两种方法分别实现了线性回归 项目传到GitHub Learn_MXNet/LinearRegression.ipynb at master · arthuryunze/Learn_MXNet 线性回归理解（附纯python实现）_Python_快来学习鸭～～～-CSDN博客</div></div></div></div><div class="relative w-100 mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-05-16-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%B8%89%E7%A7%8D%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%AD%E7%BB%83%E9%9B%86%E9%AA%8C%E8%AF%81%E9%9B%86%E6%B5%8B%E8%AF%95%E9%9B%86/ class="link black dim"></a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">机器学习中的数据集 训练集、验证集、测试集 在人工智能技术中，通常有三种常用的数据集：训练集、验证集、测试集。
先用一个不恰当的比喻来说明3种数据集之间的关系：
训练集相当于上课学知识 验证集相当于课后的的练习题，用来纠正和强化学到的知识 测试集相当于期末考试，用来最终评估学习效果 训练集 训练集（Training Dataset）是用来训练模型使用的。
机器学习的七个步骤 验证集 当我们的模型训练好之后，我们并不知道他的表现如何。
这个时候就可以使用验证集（Validation Dataset）来看看模型在新数据（验证集和测试集是不同的数据）上的表现如何。同时通过调整超参数，让模型处于最好的状态。
验证集有2个主要的作用：
评估模型效果，为了调整超参数而服务 调整超参数，使得模型在验证集上的效果最好 说明：
验证集不像训练集和测试集，它是非必需的。如果不需要调整超参数，就可以不使用验证集，直接用测试集来评估效果。 验证集评估出来的效果并非模型的最终效果，主要是用来调整超参数的，模型最终效果以测试集的评估结果为准。 测试集 当我们调好超参数后，就要开始「最终考试」了。我们通过测试集（Test Dataset）来做最终的评估。
通过测试集的评估，我们会得到一些最终的评估指标，例如：准确率、精确率、召回率、F1等。
如何合理划分数据集 下面的数据集划分方式主要针对「留出法」的验证方式，除此之外还有其他的交叉验证法，详情见下文 — — 交叉验证法。
数据划分的方法并没有明确的规定，不过可以参考3个原则：
对于小规模样本集（几万量级），常用的分配比例是 60% 训练集、20% 验证集、20% 测试集。 对于大规模样本集（百万级以上），只要验证集和测试集的数量足够即可，例如有 100w 条数据，那么留 1w 验证集，1w 测试集即可。1000w 的数据，同样留 1w 验证集和 1w 测试集。 超参数越少，或者超参数很容易调整，那么可以减少验证集的比例，更多的分配给训练集。 交叉验证法 为什么要用交叉验证法？
假如我们教小朋友学加法：1个苹果+1个苹果=2个苹果
当我们再测试的时候，会问：1个香蕉+1个香蕉=几个香蕉？
如果小朋友知道「2个香蕉」，并且换成其他东西也没有问题，那么我们认为小朋友学习会了「1+1=2」这个知识点。
如果小朋友只知道「1个苹果+1个苹果=2个苹果」，但是换成其他东西就不会了，那么我们就不能说小朋友学会了「1+1=2」这个知识点。
评估模型是否学会了「某项技能」时，也需要用新的数据来评估，而不是用训练集里的数据来评估。这种「训练集」和「测试集」完全不同的验证方法就是交叉验证法。
3 种主流的交叉验证法 留出法（Holdout cross validation） 上文提到的，按照固定比例将数据集静态的划分为训练集、验证集、测试集。的方式就是留出法。
留一法（Leave one out cross validation） 每次的测试集都只有一个样本，要进行 m 次训练和预测。 这个方法用于训练的数据只比整体数据集少了一个样本，因此最接近原始样本的分布。但是训练复杂度增加了，因为模型的数量与原始数据样本数量相同。 一般在数据缺乏时使用。</div></div></div></div></section></div></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://arthuryunze.github.io/>&copy; Yunze's blog 2022</a><div><div class=ananke-socials></div></div></div></footer></body></html>