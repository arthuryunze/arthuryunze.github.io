<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ML on Yunze's blog</title><link>https://arthuryunze.github.io/categories/ml/</link><description>Recent content in ML on Yunze's blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://arthuryunze.github.io/categories/ml/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://arthuryunze.github.io/posts/2020-02-20-softmax%E5%87%BD%E6%95%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://arthuryunze.github.io/posts/2020-02-20-softmax%E5%87%BD%E6%95%B0/</guid><description>Softmax函数 在数学，尤其是概率论和相关领域中，Softmax函数，或称归一化指数函数，是逻辑函数的一种推广。它能将一个含任意实数的K维向量z “压缩”到另一个K维实向量$ \sigma{z} $中，使得每一个元素的范围都在(0,1)之间，并且所有元素的和为1(也可视为一个 (k-1)维的hyperplan，因为总和为1，所以是subspace)。该函数的形式通常按下面的式子给出：
$$ {\displaystyle \sigma (\mathbf {z} ){j}={\frac {e^{z{j}}}{\sum {k=1}^{K}e^{z{k}}}}} for j = 1, …, K. $$
Python example：
&amp;gt;&amp;gt;&amp;gt; import numpy as np &amp;gt;&amp;gt;&amp;gt; a = [1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0] &amp;gt;&amp;gt;&amp;gt; np.exp(a) / np.sum(np.exp(a)) array([0.02364054, 0.06426166, 0.1746813, 0.474833, 0.02364054,0.06426166, 0.1746813]) Reference: Softmax函数 - 维基百科，自由的百科全书</description></item><item><title/><link>https://arthuryunze.github.io/posts/2020-02-24-loss-function/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://arthuryunze.github.io/posts/2020-02-24-loss-function/</guid><description>What’s a Loss Function? 什么是损失函数？
At its core, a loss function is incredibly simple: it’s a method of evaluating how well your algorithm models your dataset.
损失函数的核心非常简单：它是评价你的算法效果有多好的方法。
Different Types and Flavors of Loss Functions A lot of the loss functions that you see implemented in machine learning can get complex and confusing. Consider this paper from late 2017, entitled A Semantic Loss Function for Deep Learning with Symbolic Knowledge. There’s more in that title that I don’t understand than I do.</description></item><item><title/><link>https://arthuryunze.github.io/posts/2020-02-28-machinelearning%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://arthuryunze.github.io/posts/2020-02-28-machinelearning%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid><description>线性回归 线性模型 基本形式 线性模型(Linear model)试图学得一个通过属性的线性组合来进行预测的函数，即
$$ f(x)=w_1x_1+w_2x_2+&amp;hellip;+w_dx_d+b $$
一般用向量形式写成
$$ f(x)=w^Tx+b $$
其中$ w=(w_1;w_2;&amp;hellip;;w_d) $.w和b学得之后，模型就得以确定。
线性模型有很好的可解释性。
线性回归 &amp;ldquo;线性回归&amp;rdquo; (linear regression)试图学得一个线性模型以尽可能准确地预测实值输出标记。
均方误差(2.2) 是回归任务中最常用的性能度量
均方误差有非常好的几何意义。它对应了常用的欧几里得距离或简称&amp;quot;欧氏距离&amp;quot; (Euclidean distance). 基于均方误差最小化来进行模型求解的方法称为&amp;quot;最小二乘法&amp;quot; (least squ町e method).
在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小.
求解w,b过程，称为线性回归模型的最小二乘&amp;quot;参数估计&amp;quot; (parameter estimation).
凸函数的任何极小值也是最小值。严格凸函数最多有一个最小值。 凸函数 - 维基百科，自由的百科全书
两种算法：
经典算法——最小二乘法 深度学习——梯度下降法 用两种方法分别实现了线性回归 项目传到GitHub Learn_MXNet/LinearRegression.ipynb at master · arthuryunze/Learn_MXNet 线性回归理解（附纯python实现）_Python_快来学习鸭～～～-CSDN博客</description></item><item><title/><link>https://arthuryunze.github.io/posts/2020-05-16-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%B8%89%E7%A7%8D%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%AD%E7%BB%83%E9%9B%86%E9%AA%8C%E8%AF%81%E9%9B%86%E6%B5%8B%E8%AF%95%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://arthuryunze.github.io/posts/2020-05-16-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%B8%89%E7%A7%8D%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%AD%E7%BB%83%E9%9B%86%E9%AA%8C%E8%AF%81%E9%9B%86%E6%B5%8B%E8%AF%95%E9%9B%86/</guid><description>机器学习中的数据集 训练集、验证集、测试集 在人工智能技术中，通常有三种常用的数据集：训练集、验证集、测试集。
先用一个不恰当的比喻来说明3种数据集之间的关系：
训练集相当于上课学知识 验证集相当于课后的的练习题，用来纠正和强化学到的知识 测试集相当于期末考试，用来最终评估学习效果 训练集 训练集（Training Dataset）是用来训练模型使用的。
机器学习的七个步骤 验证集 当我们的模型训练好之后，我们并不知道他的表现如何。
这个时候就可以使用验证集（Validation Dataset）来看看模型在新数据（验证集和测试集是不同的数据）上的表现如何。同时通过调整超参数，让模型处于最好的状态。
验证集有2个主要的作用：
评估模型效果，为了调整超参数而服务 调整超参数，使得模型在验证集上的效果最好 说明：
验证集不像训练集和测试集，它是非必需的。如果不需要调整超参数，就可以不使用验证集，直接用测试集来评估效果。 验证集评估出来的效果并非模型的最终效果，主要是用来调整超参数的，模型最终效果以测试集的评估结果为准。 测试集 当我们调好超参数后，就要开始「最终考试」了。我们通过测试集（Test Dataset）来做最终的评估。
通过测试集的评估，我们会得到一些最终的评估指标，例如：准确率、精确率、召回率、F1等。
如何合理划分数据集 下面的数据集划分方式主要针对「留出法」的验证方式，除此之外还有其他的交叉验证法，详情见下文 — — 交叉验证法。
数据划分的方法并没有明确的规定，不过可以参考3个原则：
对于小规模样本集（几万量级），常用的分配比例是 60% 训练集、20% 验证集、20% 测试集。 对于大规模样本集（百万级以上），只要验证集和测试集的数量足够即可，例如有 100w 条数据，那么留 1w 验证集，1w 测试集即可。1000w 的数据，同样留 1w 验证集和 1w 测试集。 超参数越少，或者超参数很容易调整，那么可以减少验证集的比例，更多的分配给训练集。 交叉验证法 为什么要用交叉验证法？
假如我们教小朋友学加法：1个苹果+1个苹果=2个苹果
当我们再测试的时候，会问：1个香蕉+1个香蕉=几个香蕉？
如果小朋友知道「2个香蕉」，并且换成其他东西也没有问题，那么我们认为小朋友学习会了「1+1=2」这个知识点。
如果小朋友只知道「1个苹果+1个苹果=2个苹果」，但是换成其他东西就不会了，那么我们就不能说小朋友学会了「1+1=2」这个知识点。
评估模型是否学会了「某项技能」时，也需要用新的数据来评估，而不是用训练集里的数据来评估。这种「训练集」和「测试集」完全不同的验证方法就是交叉验证法。
3 种主流的交叉验证法 留出法（Holdout cross validation） 上文提到的，按照固定比例将数据集静态的划分为训练集、验证集、测试集。的方式就是留出法。
留一法（Leave one out cross validation） 每次的测试集都只有一个样本，要进行 m 次训练和预测。 这个方法用于训练的数据只比整体数据集少了一个样本，因此最接近原始样本的分布。但是训练复杂度增加了，因为模型的数量与原始数据样本数量相同。 一般在数据缺乏时使用。</description></item></channel></rss>