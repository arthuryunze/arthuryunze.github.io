<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Yunze's blog</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content><meta name=generator content="Hugo 0.101.0"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/ananke/css/main.min.css><link href=/posts/index.xml rel=alternate type=application/rss+xml title="Yunze's blog"><link href=/posts/index.xml rel=feed type=application/rss+xml title="Yunze's blog"><meta property="og:title" content="Posts"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://arthuryunze.github.io/posts/"><meta itemprop=name content="Posts"><meta itemprop=description content><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content></head><body class="ma0 avenir bg-near-white"><header><div class="pb3-m pb6-l bg-black"><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">Yunze's blog</a><div class="flex-l items-center"><div class=ananke-socials></div></div></div></nav><div class="tc-l pv3 ph3 ph4-ns"><h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">Posts</h1></div></div></header><main class=pb7 role=main><article class="pa3 pa4-ns nested-copy-line-height"><section class="cf ph3 ph5-l pv3 pv4-l f4 tc-l center measure-wide lh-copy mid-gray"></section><section class="flex-ns flex-wrap justify-around mt5"><div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-03-01-haskell-learn-%E4%B8%80/ class="link black dim">Haskell-learn-一</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">categories: ProgramLanguage Haskell description: Function program learning Types and Typeclasses ghci 交互式shell中，:t判断变量类型。
:t 'a' 'a' :: Char :: is read as &ldquo;has type of&rdquo;.
函数类型显式声明 一般来说，Haskell有类型推断系统，不需要我们显式声明。但是，我们定义函数时会使用显式声明的办法。
除了编写非常短的函数之外，这通常被认为是一个好的实践。
This is generally considered to be good practice except when writing very short functions.
addThree :: Int -> Int -> Int -> Int addThree x y z = x + y + z 前三个Int是参数类型，最后一个是输出类型。 参数之间用->分隔，并且参数和返回类型之间没有特殊区别。
product [1..10] 120 1到10的乘积
head takes a list of any type and returns the first element</div></div></div></div><div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-28-machinelearning%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/ class="link black dim">MachineLearning基础-线性回归</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">categories: ML description: LinearRegression 线性回归 线性模型 基本形式 线性模型(Linear model)试图学得一个通过属性的线性组合来进行预测的函数，即
$$ f(x)=w_1x_1+w_2x_2+&mldr;+w_dx_d+b $$
一般用向量形式写成
$$ f(x)=w^Tx+b $$
其中$ w=(w_1;w_2;&mldr;;w_d) $.w和b学得之后，模型就得以确定。
线性模型有很好的可解释性。
线性回归 &ldquo;线性回归&rdquo; (linear regression)试图学得一个线性模型以尽可能准确地预测实值输出标记。
均方误差(2.2) 是回归任务中最常用的性能度量
均方误差有非常好的几何意义。它对应了常用的欧几里得距离或简称"欧氏距离" (Euclidean distance). 基于均方误差最小化来进行模型求解的方法称为"最小二乘法" (least squ町e method).
在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小.
求解w,b过程，称为线性回归模型的最小二乘"参数估计" (parameter estimation).
凸函数的任何极小值也是最小值。严格凸函数最多有一个最小值。 凸函数 - 维基百科，自由的百科全书
两种算法：
经典算法——最小二乘法 深度学习——梯度下降法 用两种方法分别实现了线性回归 项目传到GitHub Learn_MXNet/LinearRegression.ipynb at master · arthuryunze/Learn_MXNet 线性回归理解（附纯python实现）_Python_快来学习鸭～～～-CSDN博客</div></div></div></div><div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-24-loss-function/ class="link black dim">Loss-Function</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">categories: ML description: learn loss function What’s a Loss Function? 什么是损失函数？
At its core, a loss function is incredibly simple: it’s a method of evaluating how well your algorithm models your dataset.
损失函数的核心非常简单：它是评价你的算法效果有多好的方法。
Different Types and Flavors of Loss Functions A lot of the loss functions that you see implemented in machine learning can get complex and confusing. Consider this paper from late 2017, entitled A Semantic Loss Function for Deep Learning with Symbolic Knowledge.</div></div></div></div><div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-23-face-detectionmtcnn-%E5%AD%A6%E4%B9%A0-%E4%B8%80/ class="link black dim">Face-Detection(MTCNN)</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">categories: ML mxnet description: learn Face Detection(MTCNN) with Deep Learning 1 Face Detection 人脸检测 对于人类而言，这是一个微不足道的问题，近来也已经被经典的基于特征的技术（例如级联分类器）合理地解决了。最近，深度学习方法已在标准的基准人脸检测数据集上取得了最先进的结果。一个例子是多任务级联卷积神经网络(Multi-task Cascade Convolutional Neural Network)，简称MTCNN。
MTCNN网络结构 该网络使用具有三个网络的级联结构。 首先将图像缩放到不同大小的范围（称为图像金字塔），然后第一个模型（建议网络或P-Net）提出候选的面部区域，第二个模型（Refine网络或R-Net）过滤边界框 ，第三个模型（输出网络或O-Net）提出了人脸标志。
第一个网络是一个浅层神经网络（后简称pnet） => 产生初步候选框 第二个网络是一个“more complex CNN“相较pnet更为复杂的网络（后简称rnet）=> 从初步候选框中筛选掉大量的不包括人脸的框
第三个网络是一个“more powerful CNN”相较rnet更为强大的网络（后简称onet）=> 进一步优化结果以及产生五个面部特征点（双眼，鼻尖，嘴角）
mtcnn库 GitHub上发现，已经有同学做好了MTCNN相应的库
ipazc/mtcnn: MTCNN face detection implementation for TensorFlow, as a PIP package.
我们先简单使用一下：
用笔记本自带摄像头拍摄一张照片，用opencv库导入。
from mtcnn import MTCNN import cv2 img = cv2.cvtColor(cv2.imread("WIN_20200223_17_44_49_Pro.jpg"), cv2.COLOR_BGR2RGB) detector = MTCNN() detector.detect_faces(img) 我们可以得到一个list格式的数据
[{'box': [480, 214, 234, 309], 'confidence': 0.</div></div></div></div><div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-21-mxnet%E5%AD%A6%E4%B9%A0-%E4%BA%8C/ class="link black dim">MXNet学习-二</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">description: Learn MXNet 2 categories: ML MXNet 在上一节，我们已经搭好了LeNet。
现在，我们要开始使用数据训练这个网络，以使它找到合适的参数。
我们将使用超参数训练LeNet。
若使用GPU进行运算，我们只需要将mx.cpu()更改为mx.gpu()，而MXNet会处理其余的工作。我们将在10个时间段(epoch)后停止训练。
建议使用GPU进行运算，LeNet比MLP(多层感知机)更复杂，计算量更大。GPU可大大加快计算速度。
为了方便，我的环境使用了CPU版本的MXNet。速度会稍慢，但不影响后续代码。
注意CPU版本和GPU版本安装时是不同的，安装步骤可以查看MXNet官网。
Initialize parameters and optimizer——初始化参数和优化器 初始化网络参数如下：
# set the context on GPU is available otherwise CPU ctx = [mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()] net.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx) trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.03}) Training——训练 # Use Accuracy as the evaluation metric. metric = mx.metric.Accuracy() softmax_cross_entropy_loss = gluon.loss.SoftmaxCrossEntropyLoss() for i in range(epoch): # Reset the train data iterator. train_data.reset() # Loop over the train data iterator.</div></div></div></div><div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-20-github-pages%E6%B7%BB%E5%8A%A0%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E6%94%AF%E6%8C%81/ class="link black dim">GitHub-Pages添加数学公式支持</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">description: 给GitHub Pages添加数学公式支持(Mathjax) categories: Github math 首先介绍一下Mathjax，Mathjax是一个开源js引擎，用于在浏览器中显示数学公式.
Mathjax MathJax | Beautiful math in all browsers.
A JavaScript display engine for mathematics that works in all browsers.
No more setup for readers. It just works.
适用于所有浏览器的数学JavaScript显示引擎。
不需要更多的设置就可以工作。
在GitHub Pages中的设置方法 找到自己jekll的主题配置文件，一般配置文件在本机主目录~/gems/gems/对应的主题路径下。(若使用remote_theme模式，可以到相应主题的GitHub主页copy相关文件。) 例如本Blog使用的thelehhman/texture主题，一般来说，_layout路径下可以配置各种页面的样式，可以看到其中每个配置文件都引入了_include路径下的head.html文件，为了我们在各种页面中都可以使用数学公式，可以在header.html文件中更改&lt;head>就可以更改每种页面的样式.
(如果希望只在部分页面使用Mathjax，可更改_layout路径下相应的文件。) 在MathJax官网中，找到它的js脚本配置如下: &lt;script src="https://polyfill.io/v3/polyfill.min.js?features=es6">&lt;/script> &lt;script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">&lt;/script> 由于Mathjax源码设置在国外服务器，直接添加此代码会导致在国内打开网页速度变得巨慢，所以，我们可以使用国内托管的Mathjax源码服务器，或者在有服务器的条件下自己搭建镜像服务器.
在这里找到了国内的一个托管服务器，mathjax | BootCDN - Bootstrap 中文网开源项目免费 CDN 加速服务
用此网站提供的地址替换掉上面代码的地址. 此时，在markdown文件中是只支持单行公式的，出于方便考虑，我们需要添加$ 公式 $ 的行内公式，添加相关配置后最终代码如下. &lt;script src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"> &lt;/script> &lt;script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], inlineMath: [['$','$']] } }); &lt;/script> 将其复制到对应html文件中即可使用.</div></div></div></div><div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-20-mxnet%E5%AD%A6%E4%B9%A0-%E4%B8%80/ class="link black dim">MXNet学习-一</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">description: Learn MXNet 1 categories: ML MXNet 系统环境：
Windows10
python3
MXNet v1.5.1 cpu版本
Anaconda jupyterLab 1.2.6
国际惯例，从mnist数据集开始。
Loading Data——导入mnist手写体数据集 import mxnet as mx # Fixing the random seed mx.random.seed(42) mnist = mx.test_utils.get_mnist() 注意，Windows环境下，运行完成后将在当前目录下载四个.qz格式文件，若下载被中断，则无法运行后续代码。
解决方法：删除不完整的.qz文件从新下载。Linux系统下该文件位置在~/.keras/datasets路径下，使用命令rm -rf "dataset name"删除。
# 训练批次 batch_size = 100 # 初始化两个迭代器，一个用于训练数据，另一个用于测试数据。 train_data = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], batch_size, shuffle=True) val_data = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size) MXNet Data iterators： MXNet数据迭代器
对于大批量数据，不可能预加载整个数据集，MXNet Data iterators可将输入数据流式传输到MXNet训练算法中。
一个批次的图像通常表示为一个4维数组(batch_size, num_channels, width, height)
Approaches——方法(CNN) CNN主要由两种网络层构成：
卷积层和池化层</div></div></div></div><div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-20-softmax%E5%87%BD%E6%95%B0/ class="link black dim">Softmax函数</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">categories: ML description: An introduction to Softmax func. Softmax函数 在数学，尤其是概率论和相关领域中，Softmax函数，或称归一化指数函数，是逻辑函数的一种推广。它能将一个含任意实数的K维向量z “压缩”到另一个K维实向量$ \sigma{z} $中，使得每一个元素的范围都在(0,1)之间，并且所有元素的和为1(也可视为一个 (k-1)维的hyperplan，因为总和为1，所以是subspace)。该函数的形式通常按下面的式子给出：
$$ {\displaystyle \sigma (\mathbf {z} ){j}={\frac {e^{z{j}}}{\sum {k=1}^{K}e^{z{k}}}}} for j = 1, …, K. $$
Python example：
>>> import numpy as np >>> a = [1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0] >>> np.exp(a) / np.sum(np.exp(a)) array([0.02364054, 0.06426166, 0.1746813, 0.474833, 0.02364054,0.06426166, 0.1746813]) Reference: Softmax函数 - 维基百科，自由的百科全书</div></div></div></div><div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-19-git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/ class="link black dim">git常用命令</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">description: Git syntax categories: Tool Git 项目提交时: git add -A 提交所有变化 git add -u 提交被修改(modified)和被删除(deleted)文件，不包括新文件(new) git add . 提交新文件(new)和被修改(modified)文件，不包括被删除(deleted)文件 git pull 拉取远程仓库,覆盖本地文件,本地其它改动不会受到影响.
项目更改时: git commit -m "本功能全部完成" 提交后
若需要撤回commit并保留代码
可执行 git reset --soft HEAD^ 以撤销上次commit
HEAD^的意思是上一个版本，也可以写成HEAD~1
如果进行了2次commit，想都撤回，可以使用HEAD~2
几个参数:
--mixed
不删除工作空间改动代码，撤销commit，并且撤销git add . 操作 这个为默认参数,即 git reset --mixed HEAD^ 和 git reset HEAD^ 效果是一样的。 --soft
不删除工作空间改动代码，撤销commit，不撤销git add . --hard
删除工作空间改动代码，撤销commit，撤销git add . 注意完成这个操作后，就恢复到了上一次的commit状态。
如果commit注释写错了，只是想改一下注释，只需要: git commit --amend
此时会进入默认vim编辑器，修改注释完毕后保存就好了。
项目拉取时 git pull 不带任何参数，拉取当前分支。</div></div></div></div><div class="relative w-100 w-30-l mb4 bg-white"><div class="relative w-100 mb4 bg-white nested-copy-line-height"><div class="bg-white mb3 pa4 gray overflow-hidden"><span class="f6 db">Posts</span><h1 class="f3 near-black"><a href=/posts/2020-02-13-markdown%E8%AF%AD%E6%B3%95/ class="link black dim">Mardown语法</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height">description: Markdown syntax categories: Tool Markdown this is ======title this is ----- title this is test > 引用内容
>> 嵌套引用
**加粗内容** 加粗
![AltText](/path/to/img.jpg) 插入图片</div></div></div></div></section><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/posts/ aria-label=Previous class=page-link role=button><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a href=/posts/ aria-label="Page 1" class=page-link role=button>1</a></li><li class="page-item active"><a aria-current=page aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/posts/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/posts/page/3/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/posts/page/3/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://arthuryunze.github.io/>&copy; Yunze's blog 2022</a><div><div class=ananke-socials></div></div></div></footer></body></html>