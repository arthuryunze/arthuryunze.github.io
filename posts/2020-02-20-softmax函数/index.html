<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Yunze's blog</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="An introduction to Softmax func."><meta name=generator content="Hugo 0.101.0"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/ananke/css/main.min.css><meta property="og:title" content><meta property="og:description" content="An introduction to Softmax func."><meta property="og:type" content="article"><meta property="og:url" content="https://arthuryunze.github.io/posts/2020-02-20-softmax%E5%87%BD%E6%95%B0/"><meta property="article:section" content="posts"><meta itemprop=name content><meta itemprop=description content="An introduction to Softmax func."><meta itemprop=wordCount content="52"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="An introduction to Softmax func."></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">Yunze's blog</a><div class="flex-l items-center"><div class=ananke-socials></div></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">POSTS</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1"></h1></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h2 id=softmax函数>Softmax函数</h2><p>在数学，尤其是概率论和相关领域中，Softmax函数，或称归一化指数函数，是逻辑函数的一种推广。它能将一个含任意实数的K维向量z “压缩”到另一个K维实向量$ \sigma{z} $中，使得每一个元素的范围都在(0,1)之间，并且所有元素的和为1(也可视为一个 (k-1)维的hyperplan，因为总和为1，所以是subspace)。该函数的形式通常按下面的式子给出：</p><p>$$ {\displaystyle \sigma (\mathbf {z} )<em>{j}={\frac {e^{z</em>{j}}}{\sum <em>{k=1}^{K}e^{z</em>{k}}}}} for j = 1, …, K. $$</p><p>Python example：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> a <span style=color:#f92672>=</span> [<span style=color:#ae81ff>1.0</span>, <span style=color:#ae81ff>2.0</span>, <span style=color:#ae81ff>3.0</span>, <span style=color:#ae81ff>4.0</span>, <span style=color:#ae81ff>1.0</span>, <span style=color:#ae81ff>2.0</span>, <span style=color:#ae81ff>3.0</span>]
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> np<span style=color:#f92672>.</span>exp(a) <span style=color:#f92672>/</span> np<span style=color:#f92672>.</span>sum(np<span style=color:#f92672>.</span>exp(a)) 
</span></span><span style=display:flex><span>array([<span style=color:#ae81ff>0.02364054</span>, <span style=color:#ae81ff>0.06426166</span>, <span style=color:#ae81ff>0.1746813</span>, <span style=color:#ae81ff>0.474833</span>, <span style=color:#ae81ff>0.02364054</span>,<span style=color:#ae81ff>0.06426166</span>, <span style=color:#ae81ff>0.1746813</span>])
</span></span></code></pre></div><h2 id=reference>Reference:</h2><p><a href=https://zh.wikipedia.org/wiki/Softmax%E5%87%BD%E6%95%B0>Softmax函数 - 维基百科，自由的百科全书</a></p><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://arthuryunze.github.io/>&copy; Yunze's blog 2022</a><div><div class=ananke-socials></div></div></div></footer></body></html>