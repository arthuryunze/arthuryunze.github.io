---
title: "机器学习中的三种数据集：训练集、验证集、测试集"
date: 2020-05-16T16:57:58+08:00
draft: false
---

---
categories: ML
description: dataset
---

# 机器学习中的数据集

## 训练集、验证集、测试集

在人工智能技术中，通常有三种常用的数据集：训练集、验证集、测试集。

先用一个不恰当的比喻来说明3种数据集之间的关系：

- 训练集相当于上课学知识
- 验证集相当于课后的的练习题，用来纠正和强化学到的知识
- 测试集相当于期末考试，用来最终评估学习效果

### 训练集

训练集（Training Dataset）是用来训练模型使用的。

机器学习的七个步骤
![机器学习的7个步骤](https://miro.medium.com/max/1400/0*mf-atTScFpQFQJbL.png)

### 验证集

当我们的模型训练好之后，我们并不知道他的表现如何。  
这个时候就可以使用验证集（Validation Dataset）来看看模型在新数据（验证集和测试集是不同的数据）上的表现如何。同时通过调整超参数，让模型处于最好的状态。

验证集有2个主要的作用：

1. 评估模型效果，为了调整超参数而服务
2. 调整超参数，使得模型在验证集上的效果最好

说明：

1. 验证集不像训练集和测试集，它是非必需的。如果不需要调整超参数，就可以不使用验证集，直接用测试集来评估效果。
2. 验证集评估出来的效果并非模型的最终效果，主要是用来调整超参数的，模型最终效果以测试集的评估结果为准。

### 测试集

当我们调好超参数后，就要开始「最终考试」了。我们通过测试集（Test Dataset）来做最终的评估。

通过测试集的评估，我们会得到一些最终的评估指标，例如：准确率、精确率、召回率、F1等。

---

## 如何合理划分数据集

![划分数据集](https://miro.medium.com/max/1400/0*PDq_o_lXUBgj-FWy.png)

下面的数据集划分方式主要针对「留出法」的验证方式，除此之外还有其他的交叉验证法，详情见下文 — — 交叉验证法。  
数据划分的方法并没有明确的规定，不过可以参考3个原则：

1. 对于小规模样本集（几万量级），常用的分配比例是 60% 训练集、20% 验证集、20% 测试集。
2. 对于大规模样本集（百万级以上），只要验证集和测试集的数量足够即可，例如有 100w 条数据，那么留 1w 验证集，1w 测试集即可。1000w 的数据，同样留 1w 验证集和 1w 测试集。
3. 超参数越少，或者超参数很容易调整，那么可以减少验证集的比例，更多的分配给训练集。

## 交叉验证法

为什么要用交叉验证法？

假如我们教小朋友学加法：1个苹果+1个苹果=2个苹果  
当我们再测试的时候，会问：1个香蕉+1个香蕉=几个香蕉？  
如果小朋友知道「2个香蕉」，并且换成其他东西也没有问题，那么我们认为小朋友学习会了「1+1=2」这个知识点。  
如果小朋友只知道「1个苹果+1个苹果=2个苹果」，但是换成其他东西就不会了，那么我们就不能说小朋友学会了「1+1=2」这个知识点。

评估模型是否学会了「某项技能」时，也需要用新的数据来评估，而不是用训练集里的数据来评估。这种「训练集」和「测试集」完全不同的验证方法就是交叉验证法。  

## 3 种主流的交叉验证法

![交叉验证法](https://miro.medium.com/max/1400/0*4bJcC94PwSNE-WEG.png)

### 留出法（Holdout cross validation）

上文提到的，按照固定比例将数据集静态的划分为训练集、验证集、测试集。的方式就是留出法。

### 留一法（Leave one out cross validation）

每次的测试集都只有一个样本，要进行 m 次训练和预测。 这个方法用于训练的数据只比整体数据集少了一个样本，因此最接近原始样本的分布。但是训练复杂度增加了，因为模型的数量与原始数据样本数量相同。 一般在数据缺乏时使用。

### k 折交叉验证（k-fold cross validation）

静态的「留出法」对数据的划分方式比较敏感，有可能不同的划分方式得到了不同的模型。「k 折交叉验证」是一种动态验证的方式，这种方式可以降低数据划分带来的影响。

具体步骤如下：

1. 将数据集分为训练集和测试集，将测试集放在一边
2. 将训练集分为 k 份
3. 每次使用 k 份中的 1 份作为验证集，其他全部作为训练集。
4. 通过 k 次训练后，我们得到了 k 个不同的模型。
5. 评估 k 个模型的效果，从中挑选效果最好的超参数
6. 使用最优的超参数，然后将 k 份数据全部作为训练集重新训练模型，得到最终模型。

![k折交叉验证](https://miro.medium.com/max/1400/0*Tkli0USuUcWbOQTC.png)

k 一般取 10 ，数据量小的时候，k 可以设大一点，这样训练集占整体比例就比较大，不过同时训练的模型个数也增多。 数据量大的时候，k 可以设小一点。

---

reference：

[一文看懂 AI 数据集：训练集、验证集、测试集（附：分割方法+交叉验证） - easyAI-人工智能知识库 - Medium](https://medium.com/@pkqiang49/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82-ai-%E6%95%B0%E6%8D%AE%E9%9B%86-%E8%AE%AD%E7%BB%83%E9%9B%86-%E9%AA%8C%E8%AF%81%E9%9B%86-%E6%B5%8B%E8%AF%95%E9%9B%86-%E9%99%84-%E5%88%86%E5%89%B2%E6%96%B9%E6%B3%95-%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-9b3afd37fd58)

[一文看懂机器学习！（3种学习方法+7个实操步骤+15种常见算法）](https://easyai.tech/ai-definition/machine-learning/)
